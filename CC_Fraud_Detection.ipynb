{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Creating Credit Card Default Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "cc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Splitting the data in training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "shuffeled_data = cc_data.sample(frac=1)\n",
    "one_hot_data = pd.get_dummies(shuffeled_data, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class_0</th>\n",
       "      <th>Class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36547</th>\n",
       "      <td>38586.0</td>\n",
       "      <td>1.242547</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>-1.206012</td>\n",
       "      <td>0.083576</td>\n",
       "      <td>2.171891</td>\n",
       "      <td>3.391877</td>\n",
       "      <td>-0.417041</td>\n",
       "      <td>0.793206</td>\n",
       "      <td>-0.149793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063843</td>\n",
       "      <td>-0.166334</td>\n",
       "      <td>1.008827</td>\n",
       "      <td>0.824605</td>\n",
       "      <td>-0.268009</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.019513</td>\n",
       "      <td>28.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183335</th>\n",
       "      <td>125755.0</td>\n",
       "      <td>1.840234</td>\n",
       "      <td>-0.792155</td>\n",
       "      <td>-0.485783</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>-0.710626</td>\n",
       "      <td>-0.035291</td>\n",
       "      <td>-0.701793</td>\n",
       "      <td>0.132440</td>\n",
       "      <td>1.349739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765471</td>\n",
       "      <td>0.028276</td>\n",
       "      <td>-0.431759</td>\n",
       "      <td>-0.202537</td>\n",
       "      <td>0.130042</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>-0.046011</td>\n",
       "      <td>74.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174305</th>\n",
       "      <td>121859.0</td>\n",
       "      <td>-0.346410</td>\n",
       "      <td>0.398823</td>\n",
       "      <td>-2.212968</td>\n",
       "      <td>-2.051168</td>\n",
       "      <td>0.598982</td>\n",
       "      <td>-2.358272</td>\n",
       "      <td>0.901844</td>\n",
       "      <td>-0.197581</td>\n",
       "      <td>-1.206912</td>\n",
       "      <td>...</td>\n",
       "      <td>2.029161</td>\n",
       "      <td>-0.162931</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>-0.968043</td>\n",
       "      <td>-0.127059</td>\n",
       "      <td>0.549542</td>\n",
       "      <td>0.291011</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223480</th>\n",
       "      <td>143401.0</td>\n",
       "      <td>1.978580</td>\n",
       "      <td>-0.939814</td>\n",
       "      <td>-0.762802</td>\n",
       "      <td>0.253799</td>\n",
       "      <td>-0.457967</td>\n",
       "      <td>0.650129</td>\n",
       "      <td>-0.939212</td>\n",
       "      <td>0.220656</td>\n",
       "      <td>-0.247096</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.049912</td>\n",
       "      <td>0.221164</td>\n",
       "      <td>-1.585685</td>\n",
       "      <td>-0.420023</td>\n",
       "      <td>-0.855866</td>\n",
       "      <td>0.061352</td>\n",
       "      <td>-0.033416</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21756</th>\n",
       "      <td>31843.0</td>\n",
       "      <td>0.676039</td>\n",
       "      <td>-1.021861</td>\n",
       "      <td>1.427135</td>\n",
       "      <td>1.897830</td>\n",
       "      <td>-1.341392</td>\n",
       "      <td>0.808811</td>\n",
       "      <td>-0.670246</td>\n",
       "      <td>0.234956</td>\n",
       "      <td>1.570924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198897</td>\n",
       "      <td>-0.351437</td>\n",
       "      <td>0.115651</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>-0.230066</td>\n",
       "      <td>0.071225</td>\n",
       "      <td>0.076753</td>\n",
       "      <td>236.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72154</th>\n",
       "      <td>54589.0</td>\n",
       "      <td>-3.227655</td>\n",
       "      <td>0.785061</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>2.017448</td>\n",
       "      <td>-0.602914</td>\n",
       "      <td>-0.510693</td>\n",
       "      <td>-0.394085</td>\n",
       "      <td>1.188413</td>\n",
       "      <td>-1.026686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.911330</td>\n",
       "      <td>-0.672515</td>\n",
       "      <td>0.406555</td>\n",
       "      <td>0.261511</td>\n",
       "      <td>-0.294445</td>\n",
       "      <td>-0.437396</td>\n",
       "      <td>-0.437684</td>\n",
       "      <td>103.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57735</th>\n",
       "      <td>48045.0</td>\n",
       "      <td>0.636301</td>\n",
       "      <td>-1.396960</td>\n",
       "      <td>0.684652</td>\n",
       "      <td>0.300106</td>\n",
       "      <td>-1.348137</td>\n",
       "      <td>0.202926</td>\n",
       "      <td>-0.442428</td>\n",
       "      <td>0.198429</td>\n",
       "      <td>1.073824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587033</td>\n",
       "      <td>-0.215823</td>\n",
       "      <td>0.061436</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.918389</td>\n",
       "      <td>-0.098144</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>295.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90635</th>\n",
       "      <td>63097.0</td>\n",
       "      <td>-0.379222</td>\n",
       "      <td>0.666056</td>\n",
       "      <td>1.635023</td>\n",
       "      <td>0.752322</td>\n",
       "      <td>0.421202</td>\n",
       "      <td>1.351683</td>\n",
       "      <td>-0.151956</td>\n",
       "      <td>0.329357</td>\n",
       "      <td>-0.006912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262376</td>\n",
       "      <td>-0.345216</td>\n",
       "      <td>-1.352353</td>\n",
       "      <td>-0.252890</td>\n",
       "      <td>-0.274783</td>\n",
       "      <td>0.111129</td>\n",
       "      <td>0.137533</td>\n",
       "      <td>9.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>20974.0</td>\n",
       "      <td>1.145263</td>\n",
       "      <td>-0.341335</td>\n",
       "      <td>1.040508</td>\n",
       "      <td>-0.683389</td>\n",
       "      <td>-0.868051</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>-0.809441</td>\n",
       "      <td>0.149747</td>\n",
       "      <td>2.789183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277774</td>\n",
       "      <td>-0.020030</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>0.382682</td>\n",
       "      <td>-0.714987</td>\n",
       "      <td>0.079995</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>10.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218957</th>\n",
       "      <td>141539.0</td>\n",
       "      <td>2.033209</td>\n",
       "      <td>-0.128261</td>\n",
       "      <td>-1.185948</td>\n",
       "      <td>0.217215</td>\n",
       "      <td>0.094261</td>\n",
       "      <td>-0.619116</td>\n",
       "      <td>0.051805</td>\n",
       "      <td>-0.133873</td>\n",
       "      <td>0.321920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633930</td>\n",
       "      <td>0.295240</td>\n",
       "      <td>-0.398967</td>\n",
       "      <td>-0.304055</td>\n",
       "      <td>0.204375</td>\n",
       "      <td>-0.072668</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "36547    38586.0  1.242547  0.010297 -1.206012  0.083576  2.171891  3.391877   \n",
       "183335  125755.0  1.840234 -0.792155 -0.485783  0.087937 -0.710626 -0.035291   \n",
       "174305  121859.0 -0.346410  0.398823 -2.212968 -2.051168  0.598982 -2.358272   \n",
       "223480  143401.0  1.978580 -0.939814 -0.762802  0.253799 -0.457967  0.650129   \n",
       "21756    31843.0  0.676039 -1.021861  1.427135  1.897830 -1.341392  0.808811   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "72154    54589.0 -3.227655  0.785061  0.872626  2.017448 -0.602914 -0.510693   \n",
       "57735    48045.0  0.636301 -1.396960  0.684652  0.300106 -1.348137  0.202926   \n",
       "90635    63097.0 -0.379222  0.666056  1.635023  0.752322  0.421202  1.351683   \n",
       "12082    20974.0  1.145263 -0.341335  1.040508 -0.683389 -0.868051  0.030415   \n",
       "218957  141539.0  2.033209 -0.128261 -1.185948  0.217215  0.094261 -0.619116   \n",
       "\n",
       "              V7        V8        V9  ...       V22       V23       V24  \\\n",
       "36547  -0.417041  0.793206 -0.149793  ... -0.063843 -0.166334  1.008827   \n",
       "183335 -0.701793  0.132440  1.349739  ...  0.765471  0.028276 -0.431759   \n",
       "174305  0.901844 -0.197581 -1.206912  ...  2.029161 -0.162931  0.130769   \n",
       "223480 -0.939212  0.220656 -0.247096  ... -1.049912  0.221164 -1.585685   \n",
       "21756  -0.670246  0.234956  1.570924  ...  0.198897 -0.351437  0.115651   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "72154  -0.394085  1.188413 -1.026686  ... -0.911330 -0.672515  0.406555   \n",
       "57735  -0.442428  0.198429  1.073824  ... -0.587033 -0.215823  0.061436   \n",
       "90635  -0.151956  0.329357 -0.006912  ...  0.262376 -0.345216 -1.352353   \n",
       "12082  -0.809441  0.149747  2.789183  ...  0.277774 -0.020030 -0.009074   \n",
       "218957  0.051805 -0.133873  0.321920  ... -0.633930  0.295240 -0.398967   \n",
       "\n",
       "             V25       V26       V27       V28  Amount  Class_0  Class_1  \n",
       "36547   0.824605 -0.268009  0.016069  0.019513   28.56        1        0  \n",
       "183335 -0.202537  0.130042 -0.000649 -0.046011   74.95        1        0  \n",
       "174305 -0.968043 -0.127059  0.549542  0.291011   20.00        1        0  \n",
       "223480 -0.420023 -0.855866  0.061352 -0.033416   74.00        1        0  \n",
       "21756   0.551672 -0.230066  0.071225  0.076753  236.79        1        0  \n",
       "...          ...       ...       ...       ...     ...      ...      ...  \n",
       "72154   0.261511 -0.294445 -0.437396 -0.437684  103.22        1        0  \n",
       "57735   0.013839  0.918389 -0.098144  0.048773  295.70        1        0  \n",
       "90635  -0.252890 -0.274783  0.111129  0.137533    9.99        1        0  \n",
       "12082   0.382682 -0.714987  0.079995  0.017729   10.85        1        0  \n",
       "218957 -0.304055  0.204375 -0.072668 -0.074245    1.98        1        0  \n",
       "\n",
       "[284807 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized Data\n",
    "norm_data = (one_hot_data - one_hot_data.min())/(one_hot_data.max() - one_hot_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class_0</th>\n",
       "      <th>Class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36547</th>\n",
       "      <td>0.223309</td>\n",
       "      <td>0.979403</td>\n",
       "      <td>0.767367</td>\n",
       "      <td>0.816515</td>\n",
       "      <td>0.255635</td>\n",
       "      <td>0.780337</td>\n",
       "      <td>0.297122</td>\n",
       "      <td>0.262815</td>\n",
       "      <td>0.793894</td>\n",
       "      <td>0.457620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507053</td>\n",
       "      <td>0.662963</td>\n",
       "      <td>0.518173</td>\n",
       "      <td>0.624194</td>\n",
       "      <td>0.381670</td>\n",
       "      <td>0.416808</td>\n",
       "      <td>0.313520</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183335</th>\n",
       "      <td>0.727783</td>\n",
       "      <td>0.989557</td>\n",
       "      <td>0.758900</td>\n",
       "      <td>0.828996</td>\n",
       "      <td>0.255828</td>\n",
       "      <td>0.760932</td>\n",
       "      <td>0.262665</td>\n",
       "      <td>0.261080</td>\n",
       "      <td>0.786806</td>\n",
       "      <td>0.509276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545740</td>\n",
       "      <td>0.665854</td>\n",
       "      <td>0.324055</td>\n",
       "      <td>0.566538</td>\n",
       "      <td>0.446690</td>\n",
       "      <td>0.416499</td>\n",
       "      <td>0.312190</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174305</th>\n",
       "      <td>0.705235</td>\n",
       "      <td>0.952409</td>\n",
       "      <td>0.771467</td>\n",
       "      <td>0.799066</td>\n",
       "      <td>0.161004</td>\n",
       "      <td>0.769749</td>\n",
       "      <td>0.239310</td>\n",
       "      <td>0.270850</td>\n",
       "      <td>0.783266</td>\n",
       "      <td>0.421204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604691</td>\n",
       "      <td>0.663014</td>\n",
       "      <td>0.399855</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>0.404693</td>\n",
       "      <td>0.426654</td>\n",
       "      <td>0.319029</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223480</th>\n",
       "      <td>0.829905</td>\n",
       "      <td>0.991907</td>\n",
       "      <td>0.757342</td>\n",
       "      <td>0.824195</td>\n",
       "      <td>0.263181</td>\n",
       "      <td>0.762633</td>\n",
       "      <td>0.269556</td>\n",
       "      <td>0.259634</td>\n",
       "      <td>0.787752</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461053</td>\n",
       "      <td>0.668718</td>\n",
       "      <td>0.168564</td>\n",
       "      <td>0.554330</td>\n",
       "      <td>0.285644</td>\n",
       "      <td>0.417643</td>\n",
       "      <td>0.312446</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21756</th>\n",
       "      <td>0.184285</td>\n",
       "      <td>0.969779</td>\n",
       "      <td>0.756476</td>\n",
       "      <td>0.862144</td>\n",
       "      <td>0.336059</td>\n",
       "      <td>0.756686</td>\n",
       "      <td>0.271152</td>\n",
       "      <td>0.261272</td>\n",
       "      <td>0.787906</td>\n",
       "      <td>0.516895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519310</td>\n",
       "      <td>0.660214</td>\n",
       "      <td>0.397818</td>\n",
       "      <td>0.608873</td>\n",
       "      <td>0.387867</td>\n",
       "      <td>0.417826</td>\n",
       "      <td>0.314681</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72154</th>\n",
       "      <td>0.315923</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>0.775542</td>\n",
       "      <td>0.852535</td>\n",
       "      <td>0.341362</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.257885</td>\n",
       "      <td>0.262955</td>\n",
       "      <td>0.798133</td>\n",
       "      <td>0.427412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467517</td>\n",
       "      <td>0.655446</td>\n",
       "      <td>0.437017</td>\n",
       "      <td>0.592586</td>\n",
       "      <td>0.377351</td>\n",
       "      <td>0.408438</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57735</th>\n",
       "      <td>0.278051</td>\n",
       "      <td>0.969104</td>\n",
       "      <td>0.752518</td>\n",
       "      <td>0.849278</td>\n",
       "      <td>0.265234</td>\n",
       "      <td>0.756641</td>\n",
       "      <td>0.265060</td>\n",
       "      <td>0.262660</td>\n",
       "      <td>0.787514</td>\n",
       "      <td>0.499771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482646</td>\n",
       "      <td>0.662228</td>\n",
       "      <td>0.390513</td>\n",
       "      <td>0.578683</td>\n",
       "      <td>0.575465</td>\n",
       "      <td>0.414699</td>\n",
       "      <td>0.314114</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90635</th>\n",
       "      <td>0.365162</td>\n",
       "      <td>0.951851</td>\n",
       "      <td>0.774286</td>\n",
       "      <td>0.865746</td>\n",
       "      <td>0.285280</td>\n",
       "      <td>0.768552</td>\n",
       "      <td>0.276610</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.788918</td>\n",
       "      <td>0.462542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522271</td>\n",
       "      <td>0.660307</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>0.563711</td>\n",
       "      <td>0.380563</td>\n",
       "      <td>0.418562</td>\n",
       "      <td>0.315915</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>0.121383</td>\n",
       "      <td>0.977750</td>\n",
       "      <td>0.763657</td>\n",
       "      <td>0.855444</td>\n",
       "      <td>0.221636</td>\n",
       "      <td>0.759873</td>\n",
       "      <td>0.263326</td>\n",
       "      <td>0.260424</td>\n",
       "      <td>0.786992</td>\n",
       "      <td>0.558862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522989</td>\n",
       "      <td>0.665136</td>\n",
       "      <td>0.381011</td>\n",
       "      <td>0.599387</td>\n",
       "      <td>0.308657</td>\n",
       "      <td>0.417987</td>\n",
       "      <td>0.313484</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218957</th>\n",
       "      <td>0.819129</td>\n",
       "      <td>0.992835</td>\n",
       "      <td>0.765905</td>\n",
       "      <td>0.816863</td>\n",
       "      <td>0.261559</td>\n",
       "      <td>0.766351</td>\n",
       "      <td>0.256795</td>\n",
       "      <td>0.265671</td>\n",
       "      <td>0.783949</td>\n",
       "      <td>0.473869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.669818</td>\n",
       "      <td>0.328474</td>\n",
       "      <td>0.560839</td>\n",
       "      <td>0.458833</td>\n",
       "      <td>0.415170</td>\n",
       "      <td>0.311617</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "36547   0.223309  0.979403  0.767367  0.816515  0.255635  0.780337  0.297122   \n",
       "183335  0.727783  0.989557  0.758900  0.828996  0.255828  0.760932  0.262665   \n",
       "174305  0.705235  0.952409  0.771467  0.799066  0.161004  0.769749  0.239310   \n",
       "223480  0.829905  0.991907  0.757342  0.824195  0.263181  0.762633  0.269556   \n",
       "21756   0.184285  0.969779  0.756476  0.862144  0.336059  0.756686  0.271152   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "72154   0.315923  0.903460  0.775542  0.852535  0.341362  0.761658  0.257885   \n",
       "57735   0.278051  0.969104  0.752518  0.849278  0.265234  0.756641  0.265060   \n",
       "90635   0.365162  0.951851  0.774286  0.865746  0.285280  0.768552  0.276610   \n",
       "12082   0.121383  0.977750  0.763657  0.855444  0.221636  0.759873  0.263326   \n",
       "218957  0.819129  0.992835  0.765905  0.816863  0.261559  0.766351  0.256795   \n",
       "\n",
       "              V7        V8        V9  ...       V22       V23       V24  \\\n",
       "36547   0.262815  0.793894  0.457620  ...  0.507053  0.662963  0.518173   \n",
       "183335  0.261080  0.786806  0.509276  ...  0.545740  0.665854  0.324055   \n",
       "174305  0.270850  0.783266  0.421204  ...  0.604691  0.663014  0.399855   \n",
       "223480  0.259634  0.787752  0.454268  ...  0.461053  0.668718  0.168564   \n",
       "21756   0.261272  0.787906  0.516895  ...  0.519310  0.660214  0.397818   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "72154   0.262955  0.798133  0.427412  ...  0.467517  0.655446  0.437017   \n",
       "57735   0.262660  0.787514  0.499771  ...  0.482646  0.662228  0.390513   \n",
       "90635   0.264430  0.788918  0.462542  ...  0.522271  0.660307  0.200005   \n",
       "12082   0.260424  0.786992  0.558862  ...  0.522989  0.665136  0.381011   \n",
       "218957  0.265671  0.783949  0.473869  ...  0.480458  0.669818  0.328474   \n",
       "\n",
       "             V25       V26       V27       V28    Amount  Class_0  Class_1  \n",
       "36547   0.624194  0.381670  0.416808  0.313520  0.001112      1.0      0.0  \n",
       "183335  0.566538  0.446690  0.416499  0.312190  0.002917      1.0      0.0  \n",
       "174305  0.523568  0.404693  0.426654  0.319029  0.000778      1.0      0.0  \n",
       "223480  0.554330  0.285644  0.417643  0.312446  0.002880      1.0      0.0  \n",
       "21756   0.608873  0.387867  0.417826  0.314681  0.009217      1.0      0.0  \n",
       "...          ...       ...       ...       ...       ...      ...      ...  \n",
       "72154   0.592586  0.377351  0.408438  0.304242  0.004018      1.0      0.0  \n",
       "57735   0.578683  0.575465  0.414699  0.314114  0.011510      1.0      0.0  \n",
       "90635   0.563711  0.380563  0.418562  0.315915  0.000389      1.0      0.0  \n",
       "12082   0.599387  0.308657  0.417987  0.313484  0.000422      1.0      0.0  \n",
       "218957  0.560839  0.458833  0.415170  0.311617  0.000077      1.0      0.0  \n",
       "\n",
       "[284807 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = norm_data.drop(['Class_0', 'Class_1'], axis=1)\n",
    "df_y = norm_data[['Class_0', 'Class_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_X,ar_y = np.asarray(df_X.values, dtype='float32'),np.asarray(df_y.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(ar_X))\n",
    "(raw_X_train, raw_y_train) = (ar_X[:train_size], ar_y[:train_size])\n",
    "(raw_X_test, raw_y_test) = (ar_X[train_size:], ar_y[train_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #Eliminating the Dataset bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of fraudulent transactions:  0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "count_legit, count_fraud = np.unique(cc_data['Class'], return_counts=True)[1]\n",
    "fraud_ratio = float(count_fraud/(count_legit + count_fraud))\n",
    "print('Percent of fraudulent transactions: ', fraud_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578.8760162601626\n"
     ]
    }
   ],
   "source": [
    "weights = 1 / fraud_ratio\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y_train[:,1] = raw_y_train[:,1] * weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/omkargokhale/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = ar_X.shape[1]\n",
    "out_dim = ar_y.shape[1]\n",
    "num_layer_1_cells = 100\n",
    "num_layer_2_cells = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_node = tf.placeholder(tf.float32,[None, input_dim], name  = 'X_train')\n",
    "y_train_node = tf.placeholder(tf.float32,[None, out_dim], name  = 'y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_node = tf.constant(raw_X_test, name = 'X_test')\n",
    "y_test_node = tf.constant(raw_y_test, name = 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # layers with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_1_node = tf.Variable(tf.zeros([input_dim, num_layer_1_cells]), name = 'weight_1')\n",
    "biases_1_node = tf.Variable(tf.zeros([num_layer_1_cells]), name = 'biases_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_2_node = tf.Variable(tf.zeros([num_layer_1_cells, num_layer_2_cells]), name = 'weight_2')\n",
    "biases_2_node = tf.Variable(tf.zeros([num_layer_2_cells]), name = 'biases_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_3_node = tf.Variable(tf.zeros([ num_layer_2_cells, out_dim]), name = 'weight_3')\n",
    "biases_3_node = tf.Variable(tf.zeros([out_dim]), name = 'biases_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Building functions to connect Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-c0ff7e9e2c97>:3: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "def network(input_tensor):\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(input_tensor, weight_1_node) + biases_1_node)\n",
    "    layer2 = tf.nn.dropout(tf.nn.sigmoid(tf.matmul(layer1, weight_2_node) + biases_2_node), 0.85)\n",
    "    layer3 = tf.nn.softmax(tf.matmul(layer2, weight_3_node) + biases_3_node)\n",
    "    return layer3\n",
    "y_train_pred = network(X_train_node)\n",
    "y_test_pred = network(X_test_node)\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(y_train_node, y_train_pred)\n",
    "optimizer = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(actual, predicted):\n",
    "    actual = np.argmax(actual, 1)\n",
    "    predicted = np.argmax(predicted, 1)\n",
    "    return (100 * np.sum(np.equal(predicted, actual)) / predicted.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Parsing data - defining epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Current loss: 1.3858 Elapsed time: 0.69 seconds\n",
      "Current accuracy: 6.76%\n",
      "Epoch: 10 Current loss: 1.3856 Elapsed time: 0.61 seconds\n",
      "Current accuracy: 26.77%\n",
      "Epoch: 20 Current loss: 1.3565 Elapsed time: 0.62 seconds\n",
      "Current accuracy: 69.91%\n",
      "Epoch: 30 Current loss: 1.2439 Elapsed time: 0.59 seconds\n",
      "Current accuracy: 87.66%\n",
      "Epoch: 40 Current loss: 1.0715 Elapsed time: 0.57 seconds\n",
      "Current accuracy: 98.05%\n",
      "Epoch: 50 Current loss: 0.9568 Elapsed time: 0.58 seconds\n",
      "Current accuracy: 98.33%\n",
      "Epoch: 60 Current loss: 0.8873 Elapsed time: 0.62 seconds\n",
      "Current accuracy: 98.93%\n",
      "Epoch: 70 Current loss: 0.8396 Elapsed time: 0.64 seconds\n",
      "Current accuracy: 99.63%\n",
      "Epoch: 80 Current loss: 0.8276 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.45%\n",
      "Epoch: 90 Current loss: 0.8158 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 99.58%\n",
      "Final accuracy: 99.35%\n",
      "Final fraud specific accuracy: 74.49%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        _, cross_entropy_score = session.run([optimizer, cross_entropy],\n",
    "                                             feed_dict={X_train_node: raw_X_train, y_train_node: raw_y_train})\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            timer = time.time() - start_time\n",
    "\n",
    "            print('Epoch: {}'.format(epoch), 'Current loss: {0:.4f}'.format(cross_entropy_score),\n",
    "                  'Elapsed time: {0:.2f} seconds'.format(timer))\n",
    "\n",
    "            final_y_test = y_test_node.eval()\n",
    "            final_y_test_prediction = y_test_pred.eval()\n",
    "            final_accuracy = calc_accuracy(final_y_test, final_y_test_prediction)\n",
    "            print(\"Current accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "    final_y_test = y_test_node.eval()\n",
    "    final_y_test_prediction = y_test_pred.eval()\n",
    "    final_accuracy = calc_accuracy(final_y_test, final_y_test_prediction)\n",
    "    print(\"Final accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "final_fraud_y_test = final_y_test[final_y_test[:, 1] == 1]\n",
    "final_fraud_y_test_prediction = final_y_test_prediction[final_y_test[:, 1] == 1]\n",
    "final_fraud_accuracy = calc_accuracy(final_fraud_y_test, final_fraud_y_test_prediction)\n",
    "print('Final fraud specific accuracy: {0:.2f}%'.format(final_fraud_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
